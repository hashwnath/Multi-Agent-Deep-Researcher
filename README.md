# Multi-Agent-Deep-Researcher
<img width="2515" height="1200" alt="architecture diagram" src="https://github.com/user-attachments/assets/4fc74b61-9faf-4f63-979f-e8ce3869adaf" />

A sophisticated multi-type research and analysis system that combines web content extraction, PDF processing, and specialized domain research to provide comprehensive insights across various research domains.

## ğŸš€ Features

### **Multi-Domain Research Capabilities**
- **Developer Tools Research**: Analyze development tools, APIs, and technologies
- **Product Research**: Compare products, features, and alternatives
- **Educational Research**: Evaluate institutions, programs, and courses
- **Financial Research**: Analyze stocks, companies, and market trends
- **Technical Documentation**: Review APIs, SDKs, and technical specifications
- **Industry Research**: Study market trends, competitors, and industry analysis
- **General Research**: Fallback for uncategorized queries

### **Intelligent Content Processing**
- **Web Content Extraction**: Advanced web scraping and content analysis
- **PDF Document Processing**: Intelligent PDF analysis with relevance scoring
- **Entity Extraction**: Automated identification of companies, products, and technologies
- **Context-Aware Analysis**: Domain-specific insights and recommendations

### **Flexible PDF Integration**
- **PDF Selection Options**:
  - Auto-select relevant PDFs
  - Manual PDF selection
  - Relevance-based PDF ranking
- **S3 Integration**: Secure PDF storage and retrieval
- **Relevance Scoring**: Intelligent PDF filtering based on query context

### **Specialized Output Formatting**
Each research type provides tailored output with domain-specific metrics and insights.

## ğŸ—ï¸ Architecture

The system uses a multi-agent architecture with specialized nodes for different research types:

- **Intent Detection Agent**: Classifies research queries
- **Content Extraction Agent**: Processes web content
- **PDF Processing Agent**: Analyzes PDF documents
- **Specialized Research Agents**: Domain-specific analysis
- **Analysis & Synthesis Agent**: Combines insights and generates recommendations

## ğŸ“‹ Prerequisites

- Python 3.8+
- AWS S3 access (for PDF storage)
- Required API keys (configured via environment variables)

## ğŸ› ï¸ Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd Advanced-Research-Agent
   ```

2. **Install dependencies**
   ```bash
   cd advanced-agent
   pip install -r requirements.txt
   ```

3. **Configure environment variables**
   ```bash
   cp .env.example .env
   # Edit .env with your API keys and configuration
   ```

4. **Run the application**
   ```bash
   python main.py
   ```

## ğŸ”§ Configuration

Create a `.env` file with the following variables:

```env
# API Keys
ANTHROPIC_API_KEY=your_anthropic_key
FIRECRAWL_API_KEY=your_firecrawl_key

# AWS Configuration
AWS_ACCESS_KEY_ID=your_aws_access_key
AWS_SECRET_ACCESS_KEY=your_aws_secret_key
AWS_REGION=us-east-2
S3_BUCKET_NAME=your_bucket_name

# Application Settings
MAX_ENTITIES=10
MAX_PDFS=5
```

## ğŸ¯ Usage

### **Basic Research**
```bash
python main.py
```

### **Research Options**
1. **Regular Research**: Auto-selects relevant PDFs
2. **Select Specific PDFs**: Choose specific PDFs for analysis
3. **Find Relevant PDFs**: Rank PDFs by relevance to query

### **Example Queries**
- "Best tools to build AI agents"
- "Compare Python web frameworks"
- "Top universities for computer science"
- "Stock analysis for tech companies"
- "API documentation for payment processing"

## ğŸ“Š Output Examples

### **Developer Tools Research**
```
1. ğŸ¢ LangChain
   ğŸŒ Website: https://langchain.com
   ğŸ’° Pricing: Freemium
   ğŸ“– Open Source: Yes
   ğŸ› ï¸ Tech Stack: Python, JavaScript, TypeScript
   ğŸ’» Language Support: Python, JavaScript, TypeScript
   ğŸ”Œ API: âœ… Available
   ğŸ”— Integrations: OpenAI, Anthropic, Pinecone
```

### **Product Research**
```
1. ğŸ“± ChatGPT
   ğŸ·ï¸ Category: AI Assistant
   ğŸŒ Website: https://chat.openai.com
   ğŸ’° Price: Free + Premium
   â­ Rating: 4.8/5
   âœ¨ Features: Natural language processing, Code generation
   ğŸ¯ Target: Developers, Content creators
```

## ğŸ”’ Security

- Environment variables for sensitive configuration
- AWS IAM roles for S3 access
- Secure API key management
- No hardcoded credentials in source code

## ğŸ“ Project Structure

```
Advanced-Research-Agent/
â”œâ”€â”€ advanced-agent/
â”‚   â”œâ”€â”€ main.py                 # Main application entry point
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ workflow.py         # Workflow orchestration
â”‚   â”‚   â”œâ”€â”€ models.py           # Data models
â”‚   â”‚   â”œâ”€â”€ prompts.py          # LLM prompts
â”‚   â”‚   â”œâ”€â”€ firecrawl.py        # Web content extraction
â”‚   â”‚   â”œâ”€â”€ pdf_notetaker.py    # PDF processing
â”‚   â”‚   â””â”€â”€ s3_pdf_service.py   # S3 PDF management
â”‚   â”œâ”€â”€ pyproject.toml          # Project configuration
â”‚   â””â”€â”€ README.md               # Agent-specific documentation
â”œâ”€â”€ simple-agent/               # Simplified version
â”œâ”€â”€ .gitignore                  # Git ignore rules
â””â”€â”€ README.md                   # This file
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Built with [LangChain](https://langchain.com/) for LLM orchestration
- Uses [Anthropic Claude](https://www.anthropic.com/) for AI analysis
- Powered by [Firecrawl](https://firecrawl.dev/) for web content extraction
- PDF processing with [pdfplumber](https://github.com/jsvine/pdfplumber) and [PyPDF2](https://pypdf2.readthedocs.io/)

## ğŸ“ Support

For questions or support, please open an issue in the GitHub repository.

---

**Note**: This is a research and development tool. Please ensure compliance with relevant terms of service and data privacy regulations when using third-party APIs and services. 
